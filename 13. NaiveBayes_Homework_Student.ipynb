{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnTZE3HF8f05"
   },
   "source": [
    "# 13장. 나이브 베이즈 (NaiveBayes)  과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYJxWp6j8npp"
   },
   "source": [
    "## 1. 데이터 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 SpamAssassin 데이터셋 다운 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lbb41k9n9QAE"
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "from scratch.machine_learning import split_data\n",
    "\n",
    "BASE_URL = \"https://spamassassin.apache.org/old/publiccorpus/\"\n",
    "FILES = [\"20021010_easy_ham.tar.bz2\",\n",
    "         \"20021010_hard_ham.tar.bz2\",\n",
    "         \"20021010_spam.tar.bz2\"]\n",
    "OUTPUT_DIR = 'spam_data'\n",
    "\n",
    "if os.path.exists(OUTPUT_DIR) is False:\n",
    "    for filename in FILES:\n",
    "        content = requests.get(f\"{BASE_URL}/{filename}\").content\n",
    "\n",
    "        fin = BytesIO(content)\n",
    "\n",
    "        with tarfile.open(fileobj=fin, mode='r:bz2') as tf:\n",
    "            tf.extractall(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 메세지 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QiuEkgoAVCyT"
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class Message(NamedTuple):\n",
    "    text: str\n",
    "    is_spam: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 이메일 본문 디코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.parser import Parser\n",
    "\n",
    "def decode_email(msg_str):\n",
    "    p = Parser()\n",
    "    message = p.parsestr(msg_str)\n",
    "    decoded_message = ''\n",
    "    for part in message.walk():\n",
    "        if part.get_content_type() not in ('text/plain', 'text/html'): continue\n",
    "\n",
    "        charset = part.get_content_charset()\n",
    "        part_str = part.get_payload(decode=1)\n",
    "        try:\n",
    "            decoded_message += part_str.decode(charset)\n",
    "        except:\n",
    "            decoded_message += str(part_str)\n",
    "\n",
    "    return decoded_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 이메일 텍스트 읽기 (Q)\n",
    "이메일의 제목과 본문 텍스트를 읽어서 Message 타입을 만들고 데이터 리스트를 생성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dIrBCKg3Wnl7"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import email\n",
    "from typing import List\n",
    "\n",
    "def read_emails(include_body : bool = False) -> List[Message]:\n",
    "    # modify the path to wherever you've put the files\n",
    "    path = 'spam_data/*/*'\n",
    "\n",
    "    data: List[Message] = []\n",
    "    # glob.glob returns every filename that matches the wildcarded path\n",
    "    for filename in glob.glob(path):\n",
    "        is_spam = \"ham\" not in filename\n",
    "\n",
    "        # There are some garbage characters in the emails, the errors='ignore'\n",
    "        # skips them instead of raising an exception.\n",
    "        with open(filename, errors='ignore') as email_file:\n",
    "            raw_email = email_file.read()\n",
    "            # your code\n",
    "            msgobj = email.message_from_string(raw_email)\n",
    "            body = decode_email(raw_email)\n",
    "            message = msgobj['Subject'] or \"\"\n",
    "            message = message + \" \" + body\n",
    "            data.append(Message(message, is_spam))\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "읽은 email 개수 : 3302\n"
     ]
    }
   ],
   "source": [
    "include_body = True\n",
    "data = read_emails(include_body= True)            \n",
    "print(\"읽은 email 개수 :\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NLTK 설치 및 테스트  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 NLTK설치 및 리소스 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\pc\\anaconda3\\envs\\data_mining\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pc\\anaconda3\\envs\\data_mining\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\pc\\anaconda3\\envs\\data_mining\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\pc\\anaconda3\\envs\\data_mining\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\pc\\anaconda3\\envs\\data_mining\\lib\\site-packages (from nltk) (2021.4.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 단어 토큰화 및 어간 추출 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens :  ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', \"Bones's\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "text=\"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
    "tokenizer=TreebankWordTokenizer()\n",
    "words = tokenizer.tokenize(text)\n",
    "print(\"tokens : \", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 불용어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords :  {'which', 'more', 'any', 'weren', \"hasn't\", 'here', 'have', 'them', 'than', 'o', 'through', 'when', 'own', \"doesn't\", 'shan', 'before', \"she's\", 'mightn', \"that'll\", 'both', 'then', 'too', 'if', 'were', 'during', 'this', 'your', 'we', 'but', 'from', 'hers', 'on', 'other', 'should', 'few', \"haven't\", \"you're\", \"you'll\", 'ain', 'do', 'i', 'off', 'am', 're', 'down', 'yourselves', 'be', 'does', 'being', 'most', 'ma', 'its', 'aren', 'between', 'while', 'these', 'to', 'yours', 'now', 'shouldn', \"you'd\", 'for', 'that', 'further', 'there', 'how', 'nor', 'will', 'or', \"didn't\", 'ourselves', \"weren't\", 'been', 't', 'under', 'wouldn', 'hasn', 'their', \"couldn't\", 'just', 'needn', 'are', 'you', 'over', 'once', \"wasn't\", 'did', \"mustn't\", 'such', 'until', 'my', 'haven', 'as', 'with', 've', 'd', 'out', \"shan't\", \"aren't\", 'she', 'into', 'only', \"won't\", \"hadn't\", 'about', 'by', 'why', 'wasn', 'because', 'itself', 'the', 'an', \"it's\", 'all', \"isn't\", \"wouldn't\", 'a', 'won', 'and', 'him', 'who', 'they', 'in', 'll', \"should've\", 'isn', 'against', 'themselves', 'couldn', 'his', 'where', 'of', \"mightn't\", \"shouldn't\", 'is', 'after', 'himself', 'some', 's', 'very', \"don't\", 'mustn', 'm', 'has', 'had', 'above', 'ours', 'whom', 'was', 'don', \"you've\", \"needn't\", 'what', 'didn', 'no', 'doesn', 'having', 'below', 'me', 'herself', 'it', 'same', 'yourself', 'our', 'again', 'can', 'so', 'y', 'those', 'each', 'hadn', 'theirs', 'myself', 'he', 'her', 'up', 'not', 'doing', 'at'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "print(\"stopwords : \", stopwords_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 어간 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem tokens :  41 ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', \"bones'\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n",
      "\n",
      "stem tokens without stopwords:  24 ['thi', 'map', 'found', 'billi', \"bones'\", 'chest', ',', 'accur', 'copi', ',', 'complet', 'thing', '--', 'name', 'height', 'sound', '--', 'singl', 'except', 'red', 'cross', 'written', 'note', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "s = PorterStemmer()\n",
    "stem_words = [s.stem(w) for w in words]\n",
    "print(\"stem tokens : \", len(stem_words), stem_words)\n",
    "print(\"\")\n",
    "stem_words_wo_stopwords = [s.stem(w) for w in words if w not in stopwords_set]\n",
    "print(\"stem tokens without stopwords: \", \n",
    "      len(stem_words_wo_stopwords),\n",
    "      stem_words_wo_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 토큰화 함수 (Q)\n",
    "Treebank Tokenizer를 사용해서 어간 추출 및 불용어 제거를 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ny6lEE8S7o7w"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from typing import Set\n",
    "\n",
    "def tokenize(text: str) -> Set[str]:\n",
    "    # your code\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    words = tokenizer.tokenize(text)\n",
    "    \n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    \n",
    "    s = PorterStemmer()\n",
    "    words = [s.stem(w) for w in words if w not in stopwords_set]\n",
    "    \n",
    "    return set(words)                       # remove duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 나이브 베이즈 분류기  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfyIAKvLUzGl"
   },
   "source": [
    "### 3.1  NaiveBayesClassifier (Q)\n",
    "단어의 최소 빈도수를 설정해서 그 이하로 나오는 단어는 무시하도록 _thresholding_tokens 함수 작성하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XrYMT3FEU2mP"
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Iterable\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, k: float = 0.5) -> None:\n",
    "        self.k = k  # smoothing factor\n",
    "\n",
    "        self.tokens: Set[str] = set()\n",
    "        self.token_spam_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.token_ham_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.spam_messages = self.ham_messages = 0\n",
    "\n",
    "    def train(self, \n",
    "              messages: Iterable[Message], \n",
    "              threshold: int = 0, \n",
    "              verbos : bool = True) -> None:\n",
    "        self._count_tokens(messages)\n",
    "        del_spam_count, del_ham_count = self._thresholding_tokens(messages, threshold)\n",
    "        \n",
    "        if verbos :\n",
    "            print(del_spam_count, \"tokens are deleted in spams \")\n",
    "            print(del_ham_count, \"tokens are deleted in hams \")\n",
    "            print(\"spam \", self.spam_messages)\n",
    "            print(\"ham \", self.ham_messages)\n",
    "            print(\"token\", len(self.tokens))\n",
    "            print(\"spam token\", len(self.token_spam_counts))\n",
    "            print(\"ham token\", len(self.token_ham_counts))\n",
    "\n",
    "            print(\"======= token probabilities ======= \")\n",
    "            self.print_token_probilities()\n",
    "    \n",
    "    def _count_tokens(self, messages: Iterable[Message]) -> None:\n",
    "        for message in messages:\n",
    "            # Increment message counts\n",
    "            if message.is_spam:\n",
    "                self.spam_messages += 1\n",
    "            else:\n",
    "                self.ham_messages += 1\n",
    "\n",
    "            # Increment word counts\n",
    "            for token in tokenize(message.text):\n",
    "                if message.is_spam:\n",
    "                    self.token_spam_counts[token] += 1\n",
    "                else:\n",
    "                    self.token_ham_counts[token] += 1\n",
    "                    \n",
    "    def _thresholding_tokens(self, \n",
    "                             messages: Iterable[Message], \n",
    "                             threshold: int = 0) -> Tuple[int, int]:\n",
    "        \n",
    "        del_spam_count = 0\n",
    "        del_ham_count = 0\n",
    "        # your code\n",
    "        for message in messages:\n",
    "            for token in tokenize(message.text):\n",
    "                if(self.token_spam_counts[token]<= threshold):\n",
    "                    #del self.token_spam_counts[token]\n",
    "                    #del_spam_count += 1\n",
    "                    self.token_spam_counts.pop(token)\n",
    "                    del_spam_count += 1\n",
    "                else:\n",
    "                    self.tokens.add(token)\n",
    "                \n",
    "                if(self.token_ham_counts[token]<=threshold):\n",
    "                    #del self.token_ham_counts[token]\n",
    "                    #del_ham_count += 1\n",
    "                    self.token_ham_counts.pop(token)\n",
    "                    del_ham_count += 1\n",
    "                else:\n",
    "                    self.tokens.add(token)\n",
    "        \n",
    "        return del_spam_count, del_ham_count\n",
    "        \n",
    "    def print_token_probilities(self, count=10):\n",
    "        for token in self.tokens:\n",
    "            p_token_spam, p_token_ham = self._probabilities(token)\n",
    "            print(token, \"(spam:\", p_token_spam, \"ham:\", p_token_ham, \")\")\n",
    "            count -= 1\n",
    "            if count == 0 : return\n",
    "\n",
    "    def token_histogram(self):\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plt.subplot(2, 1, 1)\n",
    "        n, bins, patches = plt.hist(self.token_spam_counts.values(),\n",
    "                                    200,\n",
    "                                    facecolor=\"#2E495E\",\n",
    "                                    edgecolor=(0, 0, 0))\n",
    "        plt.title(\"Spam words\")\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"Word Count\")\n",
    "\n",
    "        plt.subplot(2, 1, 2)\n",
    "        n, bins, patches = plt.hist(self.token_ham_counts.values(),\n",
    "                                    200,\n",
    "                                    facecolor=\"#2E495E\",\n",
    "                                    edgecolor=(0, 0, 0))\n",
    "        plt.title(\"Ham words\")\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"Word Count\")\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    def _probabilities(self, token: str) -> Tuple[float, float]:\n",
    "        \"\"\"returns P(token | spam) and P(token | not spam)\"\"\"\n",
    "        spam = self.token_spam_counts[token]\n",
    "        ham = self.token_ham_counts[token]\n",
    "\n",
    "        p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
    "        p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
    "\n",
    "        return p_token_spam, p_token_ham\n",
    "\n",
    "    def token_histogram(self):\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plt.subplot(2, 1, 1)\n",
    "        n, bins, patches = plt.hist(self.token_spam_counts.values(),\n",
    "                                    200,\n",
    "                                    facecolor=\"#2E495E\",\n",
    "                                    edgecolor=(0, 0, 0))\n",
    "        plt.title(\"Spam words\")\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"Word Count\")\n",
    "\n",
    "        plt.subplot(2, 1, 2)\n",
    "        n, bins, patches = plt.hist(self.token_ham_counts.values(),\n",
    "                                    200,\n",
    "                                    facecolor=\"#2E495E\",\n",
    "                                    edgecolor=(0, 0, 0))\n",
    "        plt.title(\"Ham words\")\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"Word Count\")\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    def predict(self, text: str) -> float:\n",
    "        text_tokens = tokenize(text)\n",
    "        log_prob_if_spam = log_prob_if_ham = 0.0\n",
    "\n",
    "        # Iterate through each word in our vocabulary.\n",
    "        for token in self.tokens:\n",
    "            prob_if_spam, prob_if_ham = self._probabilities(token)\n",
    "\n",
    "            # If *token* appears in the message,\n",
    "            # add the log probability of seeing it;\n",
    "            if token in text_tokens:\n",
    "                log_prob_if_spam += math.log(prob_if_spam)\n",
    "                log_prob_if_ham += math.log(prob_if_ham)\n",
    "\n",
    "            # otherwise add the log probability of _not_ seeing it\n",
    "            # which is log(1 - probability of seeing it)\n",
    "            else:\n",
    "                log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "                log_prob_if_ham += math.log(1.0 - prob_if_ham)\n",
    "\n",
    "        prob_if_spam = math.exp(log_prob_if_spam)\n",
    "        prob_if_ham = math.exp(log_prob_if_ham)\n",
    "        try :\n",
    "            posterior = prob_if_spam / (prob_if_spam + prob_if_ham)\n",
    "        except ZeroDivisionError:            \n",
    "            posterior = 0\n",
    "        \n",
    "        return posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLcGR34JWsq-"
   },
   "source": [
    "### 3.2 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QgNxx5sM7v7Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229853 tokens are deleted in spams \n",
      "128010 tokens are deleted in hams \n",
      "spam  371\n",
      "ham  2105\n",
      "token 3225\n",
      "spam token 841\n",
      "ham token 3141\n",
      "======= token probabilities ======= \n",
      "extens (spam: 0.0013440860215053765 ham: 0.01828110161443495 )\n",
      "-0500 (spam: 0.0013440860215053765 ham: 0.014957264957264958 )\n",
      "arm (spam: 0.0013440860215053765 ham: 0.013532763532763533 )\n",
      "sidebar. (spam: 0.0013440860215053765 ham: 0.011633428300094967 )\n",
      "hardwar (spam: 0.0013440860215053765 ham: 0.04962013295346629 )\n",
      "switch (spam: 0.0013440860215053765 ham: 0.024453941120607788 )\n",
      "consist (spam: 0.0013440860215053765 ham: 0.011633428300094967 )\n",
      "only. (spam: 0.06317204301075269 ham: 0.00023741690408357076 )\n",
      "'m (spam: 0.04973118279569892 ham: 0.19776828110161443 )\n",
      "announc (spam: 0.0013440860215053765 ham: 0.03917378917378917 )\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from scratch.machine_learning import split_data\n",
    "\n",
    "random.seed(0)      # just so you get the same answers as me\n",
    "train_messages, test_messages = split_data(data, 0.75)\n",
    "model = NaiveBayesClassifier()\n",
    "\n",
    "model.train(train_messages, 15)\n",
    "model.token_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEfBwdtiW0jl"
   },
   "source": [
    "### 3.3 예측 및 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zD1zHTB6WwwN",
    "outputId": "d36cafe4-5447-4d40-e65d-abfed6a77832"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "predictions = [(message, model.predict(message.text))\n",
    "               for message in test_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 혼동 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(False, False): 693, (True, True): 88, (True, False): 42, (False, True): 3})\n"
     ]
    }
   ],
   "source": [
    "# Assume that spam_probability > 0.5 corresponds to spam prediction\n",
    "# and count the combinations of (actual is_spam, predicted is_spam)\n",
    "confusion_matrix = Counter((message.is_spam, spam_probability > 0.5)\n",
    "                            for message, spam_probability in predictions)\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정확도, 정밀도, 재현율 F1점수 (Q)\n",
    "혼동 행렬 결과를 이용해서 정확도, 정밀도, 재현율 F1점수를 계산해 보시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9455205811138014\n",
      "precision:  0.676923076923077\n",
      "recall:  0.967032967032967\n",
      "f1_score:  0.7963800904977376\n"
     ]
    }
   ],
   "source": [
    "from scratch.machine_learning import accuracy, precision, recall, f1_score\n",
    "\n",
    "# your code\n",
    "tp = confusion_matrix.get((True, True))\n",
    "tn = confusion_matrix.get((False, False))\n",
    "fp = confusion_matrix.get((True, False))\n",
    "fn = confusion_matrix.get((False, True))\n",
    "\n",
    "a = accuracy(tp,fp,fn,tn)\n",
    "p = precision(tp,fp,fn,tn)\n",
    "r = recall(tp,fp,fn,tn)\n",
    "f = f1_score(tp,fp,fn,tn)\n",
    "\n",
    "print(\"accuracy: \", a)\n",
    "print(\"precision: \", p)\n",
    "print(\"recall: \", r)\n",
    "print(\"f1_score: \", f)\n",
    "#print(list(confusion_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCQ-lqiiW4D0"
   },
   "source": [
    "### 3.4 스팸과 햄을 대표하는 단어 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTBcHk7RXCEE",
    "outputId": "8791d3be-72d5-4945-83c5-ee3bf9cd0261",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spammiest_words ['out', 'affili', 'frontpag', 'opt-in', 'valuabl', '/u', 'insur', 'charset=windows-1252', 'bordercolor=', 'ff0000']\n",
      "hammiest_words ['wrote', '_______________________________________________', \"b'url\", 'seem', 'sponsor', 'set', \"'d\", 'sep', 'they', 'version']\n"
     ]
    }
   ],
   "source": [
    "def p_spam_given_token(token: str, model: NaiveBayesClassifier) -> float:\n",
    "    # We probably shouldn't call private methods, but it's for a good cause.\n",
    "    prob_if_spam, prob_if_ham = model._probabilities(token)\n",
    "\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_ham)\n",
    "\n",
    "words = sorted(model.tokens, key=lambda t: p_spam_given_token(t, model))\n",
    "\n",
    "print(\"spammiest_words\", words[-10:])\n",
    "print(\"hammiest_words\", words[:10])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NaiveBayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "data_mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
